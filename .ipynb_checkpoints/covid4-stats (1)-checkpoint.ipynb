{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/covid19-forecasting-metadata/region_metadata.csv\n",
      "/kaggle/input/covid19-forecasting-metadata/region_date_metadata.csv\n",
      "/kaggle/input/covid19-global-forecasting-week-4/train.csv\n",
      "/kaggle/input/covid19-global-forecasting-week-4/submission.csv\n",
      "/kaggle/input/covid19-global-forecasting-week-4/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Date</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>ForecastId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id Province_State Country_Region        Date  ConfirmedCases  Fatalities  \\\n",
       "0   1            NaN    Afghanistan  2020-01-22             0.0         0.0   \n",
       "1   2            NaN    Afghanistan  2020-01-23             0.0         0.0   \n",
       "2   3            NaN    Afghanistan  2020-01-24             0.0         0.0   \n",
       "3   4            NaN    Afghanistan  2020-01-25             0.0         0.0   \n",
       "4   5            NaN    Afghanistan  2020-01-26             0.0         0.0   \n",
       "\n",
       "   ForecastId  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ForecastId</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ForecastId Province_State Country_Region        Date\n",
       "13          14            NaN    Afghanistan  2020-04-15\n",
       "14          15            NaN    Afghanistan  2020-04-16\n",
       "15          16            NaN    Afghanistan  2020-04-17\n",
       "16          17            NaN    Afghanistan  2020-04-18\n",
       "17          18            NaN    Afghanistan  2020-04-19"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Date</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>ForecastId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id Province_State Country_Region        Date  ConfirmedCases  Fatalities  \\\n",
       "0  1.0            NaN    Afghanistan  2020-01-22             0.0         0.0   \n",
       "1  2.0            NaN    Afghanistan  2020-01-23             0.0         0.0   \n",
       "2  3.0            NaN    Afghanistan  2020-01-24             0.0         0.0   \n",
       "3  4.0            NaN    Afghanistan  2020-01-25             0.0         0.0   \n",
       "4  5.0            NaN    Afghanistan  2020-01-26             0.0         0.0   \n",
       "\n",
       "   ForecastId  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as KL\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "import datetime\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "train = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")\n",
    "\n",
    "region_metadata = pd.read_csv(\"/kaggle/input/covid19-forecasting-metadata/region_metadata.csv\")\n",
    "region_date_metadata = pd.read_csv(\"/kaggle/input/covid19-forecasting-metadata/region_date_metadata.csv\")\n",
    "train = train.merge(test[[\"ForecastId\", \"Province_State\", \"Country_Region\", \"Date\"]], on = [\"Province_State\", \"Country_Region\", \"Date\"], how = \"left\")\n",
    "display(train.head())\n",
    "test = test[~test.Date.isin(train.Date.unique())]\n",
    "display(test.head())\n",
    "\n",
    "df = pd.concat([train, test], sort = False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35682, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Date</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>ForecastId</th>\n",
       "      <th>geo</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>continent</th>\n",
       "      <th>population</th>\n",
       "      <th>area</th>\n",
       "      <th>density</th>\n",
       "      <th>Recoveries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2</td>\n",
       "      <td>38041754</td>\n",
       "      <td>652230</td>\n",
       "      <td>58.33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2</td>\n",
       "      <td>38041754</td>\n",
       "      <td>652230</td>\n",
       "      <td>58.33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2</td>\n",
       "      <td>38041754</td>\n",
       "      <td>652230</td>\n",
       "      <td>58.33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2</td>\n",
       "      <td>38041754</td>\n",
       "      <td>652230</td>\n",
       "      <td>58.33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2</td>\n",
       "      <td>38041754</td>\n",
       "      <td>652230</td>\n",
       "      <td>58.33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id Province_State Country_Region       Date  ConfirmedCases  Fatalities  \\\n",
       "0  1.0            NaN    Afghanistan 2020-01-22             0.0         0.0   \n",
       "1  2.0            NaN    Afghanistan 2020-01-23             0.0         0.0   \n",
       "2  3.0            NaN    Afghanistan 2020-01-24             0.0         0.0   \n",
       "3  4.0            NaN    Afghanistan 2020-01-25             0.0         0.0   \n",
       "4  5.0            NaN    Afghanistan 2020-01-26             0.0         0.0   \n",
       "\n",
       "   ForecastId          geo   lat   lon  continent  population    area  \\\n",
       "0         NaN  Afghanistan  33.0  65.0          2    38041754  652230   \n",
       "1         NaN  Afghanistan  33.0  65.0          2    38041754  652230   \n",
       "2         NaN  Afghanistan  33.0  65.0          2    38041754  652230   \n",
       "3         NaN  Afghanistan  33.0  65.0          2    38041754  652230   \n",
       "4         NaN  Afghanistan  33.0  65.0          2    38041754  652230   \n",
       "\n",
       "   density  Recoveries  \n",
       "0    58.33         0.0  \n",
       "1    58.33         0.0  \n",
       "2    58.33         0.0  \n",
       "3    58.33         0.0  \n",
       "4    58.33         0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"geo\"] = df.Country_Region.astype(str) + \": \" + df.Province_State.astype(str)\n",
    "df.loc[df.Province_State.isna(), \"geo\"] = df[df.Province_State.isna()].Country_Region\n",
    "\n",
    "df.ConfirmedCases = df.groupby(\"geo\")[\"ConfirmedCases\"].cummax()\n",
    "df.Fatalities = df.groupby(\"geo\")[\"Fatalities\"].cummax()\n",
    "\n",
    "df = df.merge(region_metadata, on = [\"Country_Region\", \"Province_State\"])\n",
    "df = df.merge(region_date_metadata, on = [\"Country_Region\", \"Province_State\", \"Date\"], how = \"left\")\n",
    "df.continent = LabelEncoder().fit_transform(df.continent)\n",
    "df.Date = pd.to_datetime(df.Date, format = \"%Y-%m-%d\")\n",
    "df.sort_values([\"geo\", \"Date\"], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train date range: 2020-01-22 00:00:00  -  2020-04-14 00:00:00\n",
      "Test date range: 2020-04-02 00:00:00  -  2020-05-14 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35682, 143)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DAYS_SINCE_CASES = [1, 10, 50, 100, 500, 1000, 5000, 10000]\n",
    "min_date_train = np.min(df[~df.Id.isna()].Date)\n",
    "max_date_train = np.max(df[~df.Id.isna()].Date)\n",
    "\n",
    "min_date_test = np.min(df[~df.ForecastId.isna()].Date)\n",
    "max_date_test = np.max(df[~df.ForecastId.isna()].Date)\n",
    "\n",
    "n_dates_test = len(df[~df.ForecastId.isna()].Date.unique())\n",
    "\n",
    "print(\"Train date range:\", str(min_date_train), \" - \", str(max_date_train))\n",
    "print(\"Test date range:\", str(min_date_test), \" - \", str(max_date_test))\n",
    "\n",
    "# creating lag features\n",
    "for lag in range(1, 41):\n",
    "    df[f\"lag_{lag}_cc\"] = df.groupby(\"geo\")[\"ConfirmedCases\"].shift(lag)\n",
    "    df[f\"lag_{lag}_ft\"] = df.groupby(\"geo\")[\"Fatalities\"].shift(lag)\n",
    "    df[f\"lag_{lag}_rc\"] = df.groupby(\"geo\")[\"Recoveries\"].shift(lag)\n",
    "\n",
    "for case in DAYS_SINCE_CASES:\n",
    "    df = df.merge(df[df.ConfirmedCases >= case].groupby(\"geo\")[\"Date\"].min().reset_index().rename(columns = {\"Date\": f\"case_{case}_date\"}), on = \"geo\", how = \"left\")\n",
    "df.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df, gap):\n",
    "    \n",
    "    df[\"perc_1_ac\"] = (df[f\"lag_{gap}_cc\"] - df[f\"lag_{gap}_ft\"] - df[f\"lag_{gap}_rc\"]) / df[f\"lag_{gap}_cc\"]\n",
    "    df[\"perc_1_cc\"] = df[f\"lag_{gap}_cc\"] / df.population\n",
    "    \n",
    "    df[\"diff_1_cc\"] = df[f\"lag_{gap}_cc\"] - df[f\"lag_{gap + 1}_cc\"]\n",
    "    df[\"diff_2_cc\"] = df[f\"lag_{gap + 1}_cc\"] - df[f\"lag_{gap + 2}_cc\"]\n",
    "    df[\"diff_3_cc\"] = df[f\"lag_{gap + 2}_cc\"] - df[f\"lag_{gap + 3}_cc\"]\n",
    "    \n",
    "    df[\"diff_1_ft\"] = df[f\"lag_{gap}_ft\"] - df[f\"lag_{gap + 1}_ft\"]\n",
    "    df[\"diff_2_ft\"] = df[f\"lag_{gap + 1}_ft\"] - df[f\"lag_{gap + 2}_ft\"]\n",
    "    df[\"diff_3_ft\"] = df[f\"lag_{gap + 2}_ft\"] - df[f\"lag_{gap + 3}_ft\"]\n",
    "    \n",
    "    df[\"diff_123_cc\"] = (df[f\"lag_{gap}_cc\"] - df[f\"lag_{gap + 3}_cc\"]) / 3\n",
    "    df[\"diff_123_ft\"] = (df[f\"lag_{gap}_ft\"] - df[f\"lag_{gap + 3}_ft\"]) / 3\n",
    "\n",
    "    df[\"diff_change_1_cc\"] = df.diff_1_cc / df.diff_2_cc\n",
    "    df[\"diff_change_2_cc\"] = df.diff_2_cc / df.diff_3_cc\n",
    "    \n",
    "    df[\"diff_change_1_ft\"] = df.diff_1_ft / df.diff_2_ft\n",
    "    df[\"diff_change_2_ft\"] = df.diff_2_ft / df.diff_3_ft\n",
    "\n",
    "    df[\"diff_change_12_cc\"] = (df.diff_change_1_cc + df.diff_change_2_cc) / 2\n",
    "    df[\"diff_change_12_ft\"] = (df.diff_change_1_ft + df.diff_change_2_ft) / 2\n",
    "    \n",
    "    df[\"change_1_cc\"] = df[f\"lag_{gap}_cc\"] / df[f\"lag_{gap + 1}_cc\"]\n",
    "    df[\"change_2_cc\"] = df[f\"lag_{gap + 1}_cc\"] / df[f\"lag_{gap + 2}_cc\"]\n",
    "    df[\"change_3_cc\"] = df[f\"lag_{gap + 2}_cc\"] / df[f\"lag_{gap + 3}_cc\"]\n",
    "\n",
    "    df[\"change_1_ft\"] = df[f\"lag_{gap}_ft\"] / df[f\"lag_{gap + 1}_ft\"]\n",
    "    df[\"change_2_ft\"] = df[f\"lag_{gap + 1}_ft\"] / df[f\"lag_{gap + 2}_ft\"]\n",
    "    df[\"change_3_ft\"] = df[f\"lag_{gap + 2}_ft\"] / df[f\"lag_{gap + 3}_ft\"]\n",
    "\n",
    "    df[\"change_123_cc\"] = df[f\"lag_{gap}_cc\"] / df[f\"lag_{gap + 3}_cc\"]\n",
    "    df[\"change_123_ft\"] = df[f\"lag_{gap}_ft\"] / df[f\"lag_{gap + 3}_ft\"]\n",
    "    \n",
    "    for case in DAYS_SINCE_CASES:\n",
    "        df[f\"days_since_{case}_case\"] = (df[f\"case_{case}_date\"] - df.Date).astype(\"timedelta64[D]\")\n",
    "        df.loc[df[f\"days_since_{case}_case\"] < gap, f\"days_since_{case}_case\"] = np.nan\n",
    "\n",
    "    df[\"country_flag\"] = df.Province_State.isna().astype(int)\n",
    "    df[\"density\"] = df.population / df.area\n",
    "    \n",
    "    # target variable is log of change from last known value\n",
    "    df[\"target_cc\"] = np.log1p(df.ConfirmedCases) - np.log1p(df[f\"lag_{gap}_cc\"])\n",
    "    df[\"target_ft\"] = np.log1p(df.Fatalities) - np.log1p(df[f\"lag_{gap}_ft\"])\n",
    "    \n",
    "    features = [\n",
    "        f\"lag_{gap}_cc\",\n",
    "        f\"lag_{gap}_ft\",\n",
    "        f\"lag_{gap}_rc\",\n",
    "        \"perc_1_ac\",\n",
    "        \"perc_1_cc\",\n",
    "        \"diff_1_cc\",\n",
    "        \"diff_2_cc\",\n",
    "        \"diff_3_cc\",\n",
    "        \"diff_1_ft\",\n",
    "        \"diff_2_ft\",\n",
    "        \"diff_3_ft\",\n",
    "        \"diff_123_cc\",\n",
    "        \"diff_123_ft\",\n",
    "        \"diff_change_1_cc\",\n",
    "        \"diff_change_2_cc\",\n",
    "        \"diff_change_1_ft\",\n",
    "        \"diff_change_2_ft\",\n",
    "        \"diff_change_12_cc\",\n",
    "        \"diff_change_12_ft\",\n",
    "        \"change_1_cc\",\n",
    "        \"change_2_cc\",\n",
    "        \"change_3_cc\",\n",
    "        \"change_1_ft\",\n",
    "        \"change_2_ft\",\n",
    "        \"change_3_ft\",\n",
    "        \"change_123_cc\",\n",
    "        \"change_123_ft\",\n",
    "        \"days_since_1_case\",\n",
    "        \"days_since_10_case\",\n",
    "        \"days_since_50_case\",\n",
    "        \"days_since_100_case\",\n",
    "        \"days_since_500_case\",\n",
    "        \"days_since_1000_case\",\n",
    "        \"days_since_5000_case\",\n",
    "        \"days_since_10000_case\",\n",
    "        \"country_flag\",\n",
    "        \"lat\",\n",
    "        \"lon\",\n",
    "        \"continent\",\n",
    "        \"population\",\n",
    "        \"area\",\n",
    "        \"density\",\n",
    "        \"target_cc\",\n",
    "        \"target_ft\"\n",
    "    ]\n",
    "    return df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_predict_lgbm(df_train, df_test, gap):\n",
    "    \n",
    "    df_train.dropna(subset = [\"target_cc\", \"target_ft\", f\"lag_{gap}_cc\", f\"lag_{gap}_ft\"], inplace = True)\n",
    "    \n",
    "    target_cc = df_train.target_cc\n",
    "    target_ft = df_train.target_ft\n",
    "    \n",
    "    test_lag_cc = df_test[f\"lag_{gap}_cc\"].values\n",
    "    test_lag_ft = df_test[f\"lag_{gap}_ft\"].values\n",
    "    \n",
    "    df_train.drop([\"target_cc\", \"target_ft\"], axis = 1, inplace = True)\n",
    "    df_test.drop([\"target_cc\", \"target_ft\"], axis = 1, inplace = True)\n",
    "    \n",
    "    categorical_features = [\"continent\"]\n",
    "    \n",
    "    dtrain_cc = lgb.Dataset(df_train, label = target_cc, categorical_feature = categorical_features)\n",
    "    dtrain_ft = lgb.Dataset(df_train, label = target_ft, categorical_feature = categorical_features)\n",
    "\n",
    "    model_cc = lgb.train(LGB_PARAMS, train_set = dtrain_cc, num_boost_round = 200)\n",
    "    model_ft = lgb.train(LGB_PARAMS, train_set = dtrain_ft, num_boost_round = 200)\n",
    "    \n",
    "    # inverse transform from log of change from last known value\n",
    "    y_pred_cc = np.expm1(model_cc.predict(df_test, num_boost_round = 200) + np.log1p(test_lag_cc))\n",
    "    y_pred_ft = np.expm1(model_ft.predict(df_test, num_boost_round = 200) + np.log1p(test_lag_ft))\n",
    "    \n",
    "    return y_pred_cc, y_pred_ft, model_cc, model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mad(df_test, gap, val = False):\n",
    "    \n",
    "    df_test[\"avg_diff_cc\"] = (df_test[f\"lag_{gap}_cc\"] - df_test[f\"lag_{gap + 3}_cc\"]) / 3\n",
    "    df_test[\"avg_diff_ft\"] = (df_test[f\"lag_{gap}_ft\"] - df_test[f\"lag_{gap + 3}_ft\"]) / 3\n",
    "\n",
    "    if val:\n",
    "        y_pred_cc = df_test[f\"lag_{gap}_cc\"] + gap * df_test.avg_diff_cc - (1 - MAD_FACTOR) * df_test.avg_diff_cc * np.sum([x for x in range(gap)]) / VAL_DAYS\n",
    "        y_pred_ft = df_test[f\"lag_{gap}_ft\"] + gap * df_test.avg_diff_ft - (1 - MAD_FACTOR) * df_test.avg_diff_ft * np.sum([x for x in range(gap)]) / VAL_DAYS\n",
    "    else:\n",
    "        y_pred_cc = df_test[f\"lag_{gap}_cc\"] + gap * df_test.avg_diff_cc - (1 - MAD_FACTOR) * df_test.avg_diff_cc * np.sum([x for x in range(gap)]) / n_dates_test\n",
    "        y_pred_ft = df_test[f\"lag_{gap}_ft\"] + gap * df_test.avg_diff_ft - (1 - MAD_FACTOR) * df_test.avg_diff_ft * np.sum([x for x in range(gap)]) / n_dates_test\n",
    "\n",
    "    return y_pred_cc, y_pred_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 23\n",
    "\n",
    "LGB_PARAMS = {\"objective\": \"regression\",\n",
    "              \"num_leaves\": 6,\n",
    "              \"learning_rate\": 0.013,\n",
    "              \"bagging_fraction\": 0.91,\n",
    "              \"feature_fraction\": 0.81,\n",
    "              \"reg_alpha\": 0.13,\n",
    "              \"reg_lambda\": 0.13,\n",
    "              \"metric\": \"rmse\",\n",
    "              \"seed\": SEED\n",
    "             }\n",
    "VAL_DAYS = 7\n",
    "MAD_FACTOR = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Date: 2020-04-02T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-03T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-04T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-05T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-06T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-07T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-08T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-09T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-10T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-11T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-12T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-13T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-14T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-15T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-16T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-17T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-18T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-19T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-20T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-21T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-22T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-23T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-24T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-25T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-26T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-27T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-28T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-29T00:00:00.000000000\n",
      "[INFO] Date: 2020-04-30T00:00:00.000000000\n",
      "[INFO] Date: 2020-05-01T00:00:00.000000000\n",
      "[INFO] Date: 2020-05-02T00:00:00.000000000\n",
      "[INFO] Date: 2020-05-03T00:00:00.000000000\n",
      "[INFO] Date: 2020-05-04T00:00:00.000000000\n",
      "[INFO] Date: 2020-05-05T00:00:00.000000000\n",
      "[INFO] Date: 2020-05-06T00:00:00.000000000\n",
      "[INFO] Date: 2020-05-07T00:00:00.000000000\n",
      "[INFO] Date: 2020-05-08T00:00:00.000000000\n",
      "[INFO] Date: 2020-05-09T00:00:00.000000000\n",
      "[INFO] Date: 2020-05-10T00:00:00.000000000\n",
      "[INFO] Date: 2020-05-11T00:00:00.000000000\n",
      "[INFO] Date: 2020-05-12T00:00:00.000000000\n",
      "[INFO] Date: 2020-05-13T00:00:00.000000000\n",
      "[INFO] Date: 2020-05-14T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "df_train = df[~df.Id.isna()]\n",
    "df_test_full = df[~df.ForecastId.isna()]\n",
    "\n",
    "df_preds_val = []\n",
    "df_preds_test = []\n",
    "\n",
    "for date in df_test_full.Date.unique():\n",
    "    \n",
    "    print(\"[INFO] Date:\", date)\n",
    "    \n",
    "    # ignore date already present in train data\n",
    "    if date in df_train.Date.values:\n",
    "        df_pred_test = df_test_full.loc[df_test_full.Date == date, [\"ForecastId\", \"ConfirmedCases\", \"Fatalities\"]].rename(columns = {\"ConfirmedCases\": \"ConfirmedCases_test\", \"Fatalities\": \"Fatalities_test\"})\n",
    "    else:\n",
    "        df_test = df_test_full[df_test_full.Date == date]\n",
    "        \n",
    "        gap = (pd.Timestamp(date) - max_date_train).days\n",
    "        \n",
    "        if gap <= VAL_DAYS:\n",
    "            val_date = max_date_train - pd.Timedelta(VAL_DAYS, \"D\") + pd.Timedelta(gap, \"D\")\n",
    "\n",
    "            df_build = df_train[df_train.Date < val_date]\n",
    "            df_val = df_train[df_train.Date == val_date]\n",
    "            \n",
    "            X_build = prepare_features(df_build, gap)\n",
    "            X_val = prepare_features(df_val, gap)\n",
    "            \n",
    "            y_val_cc_lgb, y_val_ft_lgb, _, _ = build_predict_lgbm(X_build, X_val, gap)\n",
    "            y_val_cc_mad, y_val_ft_mad = predict_mad(df_val, gap, val = True)\n",
    "            \n",
    "            df_pred_val = pd.DataFrame({\"Id\": df_val.Id.values,\n",
    "                                        \"ConfirmedCases_val_lgb\": y_val_cc_lgb,\n",
    "                                        \"Fatalities_val_lgb\": y_val_ft_lgb,\n",
    "                                        \"ConfirmedCases_val_mad\": y_val_cc_mad,\n",
    "                                        \"Fatalities_val_mad\": y_val_ft_mad,\n",
    "                                       })\n",
    "\n",
    "            df_preds_val.append(df_pred_val)\n",
    "\n",
    "        X_train = prepare_features(df_train, gap)\n",
    "        X_test = prepare_features(df_test, gap)\n",
    "\n",
    "        y_test_cc_lgb, y_test_ft_lgb, model_cc, model_ft = build_predict_lgbm(X_train, X_test, gap)\n",
    "        y_test_cc_mad, y_test_ft_mad = predict_mad(df_test, gap)\n",
    "        \n",
    "        if gap == 1:\n",
    "            model_1_cc = model_cc\n",
    "            model_1_ft = model_ft\n",
    "            features_1 = X_train.columns.values\n",
    "        elif gap == 14:\n",
    "            model_14_cc = model_cc\n",
    "            model_14_ft = model_ft\n",
    "            features_14 = X_train.columns.values\n",
    "        elif gap == 28:\n",
    "            model_28_cc = model_cc\n",
    "            model_28_ft = model_ft\n",
    "            features_28 = X_train.columns.values\n",
    "\n",
    "        df_pred_test = pd.DataFrame({\"ForecastId\": df_test.ForecastId.values,\n",
    "                                     \"ConfirmedCases_test_lgb\": y_test_cc_lgb,\n",
    "                                     \"Fatalities_test_lgb\": y_test_ft_lgb,\n",
    "                                     \"ConfirmedCases_test_mad\": y_test_cc_mad,\n",
    "                                     \"Fatalities_test_mad\": y_test_ft_mad,\n",
    "                                    })\n",
    "    \n",
    "    df_preds_test.append(df_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB CC RMSLE Val of 7 days for CC: 0.21\n",
      "LGB FT RMSLE Val of 7 days for FT: 0.2\n",
      "LGB Overall RMSLE Val of 7 days: 0.2\n",
      "MAD CC RMSLE Val of 7 days for CC: 0.19\n",
      "MAD FT RMSLE Val of 7 days for FT: 0.22\n",
      "MAD Overall RMSLE Val of 7 days: 0.2\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(pd.concat(df_preds_val, sort = False), on = \"Id\", how = \"left\")\n",
    "df = df.merge(pd.concat(df_preds_test, sort = False), on = \"ForecastId\", how = \"left\")\n",
    "\n",
    "rmsle_cc_lgb = np.sqrt(mean_squared_error(np.log1p(df[~df.ConfirmedCases_val_lgb.isna()].ConfirmedCases), np.log1p(df[~df.ConfirmedCases_val_lgb.isna()].ConfirmedCases_val_lgb)))\n",
    "rmsle_ft_lgb = np.sqrt(mean_squared_error(np.log1p(df[~df.Fatalities_val_lgb.isna()].Fatalities), np.log1p(df[~df.Fatalities_val_lgb.isna()].Fatalities_val_lgb)))\n",
    "\n",
    "rmsle_cc_mad = np.sqrt(mean_squared_error(np.log1p(df[~df.ConfirmedCases_val_mad.isna()].ConfirmedCases), np.log1p(df[~df.ConfirmedCases_val_mad.isna()].ConfirmedCases_val_mad)))\n",
    "rmsle_ft_mad = np.sqrt(mean_squared_error(np.log1p(df[~df.Fatalities_val_mad.isna()].Fatalities), np.log1p(df[~df.Fatalities_val_mad.isna()].Fatalities_val_mad)))\n",
    "\n",
    "print(\"LGB CC RMSLE Val of\", VAL_DAYS, \"days for CC:\", round(rmsle_cc_lgb, 2))\n",
    "print(\"LGB FT RMSLE Val of\", VAL_DAYS, \"days for FT:\", round(rmsle_ft_lgb, 2))\n",
    "print(\"LGB Overall RMSLE Val of\", VAL_DAYS, \"days:\", round((rmsle_cc_lgb + rmsle_ft_lgb) / 2, 2))\n",
    "print(\"MAD CC RMSLE Val of\", VAL_DAYS, \"days for CC:\", round(rmsle_cc_mad, 2))\n",
    "print(\"MAD FT RMSLE Val of\", VAL_DAYS, \"days for FT:\", round(rmsle_ft_mad, 2))\n",
    "print(\"MAD Overall RMSLE Val of\", VAL_DAYS, \"days:\", round((rmsle_cc_mad + rmsle_ft_mad) / 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ForecastId</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "      <th>Fatalities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>281.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>299.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>349.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>367.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ForecastId  ConfirmedCases  Fatalities\n",
       "0           1           273.0         6.0\n",
       "1           2           281.0         6.0\n",
       "2           3           299.0         7.0\n",
       "3           4           349.0         7.0\n",
       "4           5           367.0        11.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.loc[~df.ForecastId.isna(), [\"ForecastId\", \"Country_Region\", \"Province_State\", \"Date\",\n",
    "                                                     \"ConfirmedCases_test\", \"ConfirmedCases_test_lgb\", \"ConfirmedCases_test_mad\",\n",
    "                                                     \"Fatalities_test\", \"Fatalities_test_lgb\", \"Fatalities_test_mad\"]].reset_index()\n",
    "\n",
    "test[\"ConfirmedCases\"] = 0.15 * test.ConfirmedCases_test_lgb + 0.85 * test.ConfirmedCases_test_mad\n",
    "test[\"Fatalities\"] = 0.1 * test.Fatalities_test_lgb + 0.9 * test.Fatalities_test_mad\n",
    "\n",
    "test.loc[test.Country_Region.isin([\"China\", \"US\", \"Diamond Princess\"]), \"ConfirmedCases\"] = test[test.Country_Region.isin([\"China\", \"US\", \"Diamond Princess\"])].ConfirmedCases_test_mad.values\n",
    "test.loc[test.Country_Region.isin([\"China\", \"US\", \"Diamond Princess\"]), \"Fatalities\"] = test[test.Country_Region.isin([\"China\", \"US\", \"Diamond Princess\"])].Fatalities_test_mad.values\n",
    "\n",
    "test.loc[test.Date.isin(df_train.Date.values), \"ConfirmedCases\"] = test[test.Date.isin(df_train.Date.values)].ConfirmedCases_test.values\n",
    "test.loc[test.Date.isin(df_train.Date.values), \"Fatalities\"] = test[test.Date.isin(df_train.Date.values)].Fatalities_test.values\n",
    "\n",
    "sub0 = test[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\"]]\n",
    "sub0.ForecastId = sub0.ForecastId.astype(int)\n",
    "\n",
    "sub0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13459, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ForecastId</th>\n",
       "      <th>Date</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>ConfirmedCases_test_mad</th>\n",
       "      <th>Fatalities_test_mad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6020</th>\n",
       "      <td>6021.0</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6021</th>\n",
       "      <td>6022.0</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6022</th>\n",
       "      <td>6023.0</td>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6023</th>\n",
       "      <td>6024.0</td>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6024</th>\n",
       "      <td>6025.0</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025</th>\n",
       "      <td>6026.0</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026</th>\n",
       "      <td>6027.0</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6027</th>\n",
       "      <td>6028.0</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6028</th>\n",
       "      <td>6029.0</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6029</th>\n",
       "      <td>6030.0</td>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6030</th>\n",
       "      <td>6031.0</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6031</th>\n",
       "      <td>6032.0</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6032</th>\n",
       "      <td>6033.0</td>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6033</th>\n",
       "      <td>6034.0</td>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>India</td>\n",
       "      <td>12500.666667</td>\n",
       "      <td>428.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6034</th>\n",
       "      <td>6035.0</td>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>India</td>\n",
       "      <td>13502.546512</td>\n",
       "      <td>462.593023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>6036.0</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>India</td>\n",
       "      <td>14492.639535</td>\n",
       "      <td>496.779070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6037.0</td>\n",
       "      <td>2020-04-18</td>\n",
       "      <td>India</td>\n",
       "      <td>15470.945736</td>\n",
       "      <td>530.558140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6038.0</td>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>India</td>\n",
       "      <td>16437.465116</td>\n",
       "      <td>563.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6039.0</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>India</td>\n",
       "      <td>17392.197674</td>\n",
       "      <td>596.895349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6040.0</td>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>India</td>\n",
       "      <td>18335.143411</td>\n",
       "      <td>629.453488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6040</th>\n",
       "      <td>6041.0</td>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>India</td>\n",
       "      <td>19266.302326</td>\n",
       "      <td>661.604651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6041</th>\n",
       "      <td>6042.0</td>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>India</td>\n",
       "      <td>20185.674419</td>\n",
       "      <td>693.348837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6042</th>\n",
       "      <td>6043.0</td>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>India</td>\n",
       "      <td>21093.259690</td>\n",
       "      <td>724.686047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>6044.0</td>\n",
       "      <td>2020-04-25</td>\n",
       "      <td>India</td>\n",
       "      <td>21989.058140</td>\n",
       "      <td>755.616279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044</th>\n",
       "      <td>6045.0</td>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>India</td>\n",
       "      <td>22873.069767</td>\n",
       "      <td>786.139535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>6046.0</td>\n",
       "      <td>2020-04-27</td>\n",
       "      <td>India</td>\n",
       "      <td>23745.294574</td>\n",
       "      <td>816.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>6047.0</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>India</td>\n",
       "      <td>24605.732558</td>\n",
       "      <td>845.965116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>6048.0</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>India</td>\n",
       "      <td>25454.383721</td>\n",
       "      <td>875.267442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>6049.0</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>India</td>\n",
       "      <td>26291.248062</td>\n",
       "      <td>904.162791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>6050.0</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>India</td>\n",
       "      <td>27116.325581</td>\n",
       "      <td>932.651163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>6051.0</td>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>India</td>\n",
       "      <td>27929.616279</td>\n",
       "      <td>960.732558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6051</th>\n",
       "      <td>6052.0</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>India</td>\n",
       "      <td>28731.120155</td>\n",
       "      <td>988.406977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>6053.0</td>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>India</td>\n",
       "      <td>29520.837209</td>\n",
       "      <td>1015.674419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>6054.0</td>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>India</td>\n",
       "      <td>30298.767442</td>\n",
       "      <td>1042.534884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>6055.0</td>\n",
       "      <td>2020-05-06</td>\n",
       "      <td>India</td>\n",
       "      <td>31064.910853</td>\n",
       "      <td>1068.988372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>6056.0</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>India</td>\n",
       "      <td>31819.267442</td>\n",
       "      <td>1095.034884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6056</th>\n",
       "      <td>6057.0</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>India</td>\n",
       "      <td>32561.837209</td>\n",
       "      <td>1120.674419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>6058.0</td>\n",
       "      <td>2020-05-09</td>\n",
       "      <td>India</td>\n",
       "      <td>33292.620155</td>\n",
       "      <td>1145.906977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6058</th>\n",
       "      <td>6059.0</td>\n",
       "      <td>2020-05-10</td>\n",
       "      <td>India</td>\n",
       "      <td>34011.616279</td>\n",
       "      <td>1170.732558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6059</th>\n",
       "      <td>6060.0</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>India</td>\n",
       "      <td>34718.825581</td>\n",
       "      <td>1195.151163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6060</th>\n",
       "      <td>6061.0</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>India</td>\n",
       "      <td>35414.248062</td>\n",
       "      <td>1219.162791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>6062.0</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>India</td>\n",
       "      <td>36097.883721</td>\n",
       "      <td>1242.767442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>6063.0</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>India</td>\n",
       "      <td>36769.732558</td>\n",
       "      <td>1265.965116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ForecastId       Date Country_Region  ConfirmedCases_test_mad  \\\n",
       "6020      6021.0 2020-04-02          India                      NaN   \n",
       "6021      6022.0 2020-04-03          India                      NaN   \n",
       "6022      6023.0 2020-04-04          India                      NaN   \n",
       "6023      6024.0 2020-04-05          India                      NaN   \n",
       "6024      6025.0 2020-04-06          India                      NaN   \n",
       "6025      6026.0 2020-04-07          India                      NaN   \n",
       "6026      6027.0 2020-04-08          India                      NaN   \n",
       "6027      6028.0 2020-04-09          India                      NaN   \n",
       "6028      6029.0 2020-04-10          India                      NaN   \n",
       "6029      6030.0 2020-04-11          India                      NaN   \n",
       "6030      6031.0 2020-04-12          India                      NaN   \n",
       "6031      6032.0 2020-04-13          India                      NaN   \n",
       "6032      6033.0 2020-04-14          India                      NaN   \n",
       "6033      6034.0 2020-04-15          India             12500.666667   \n",
       "6034      6035.0 2020-04-16          India             13502.546512   \n",
       "6035      6036.0 2020-04-17          India             14492.639535   \n",
       "6036      6037.0 2020-04-18          India             15470.945736   \n",
       "6037      6038.0 2020-04-19          India             16437.465116   \n",
       "6038      6039.0 2020-04-20          India             17392.197674   \n",
       "6039      6040.0 2020-04-21          India             18335.143411   \n",
       "6040      6041.0 2020-04-22          India             19266.302326   \n",
       "6041      6042.0 2020-04-23          India             20185.674419   \n",
       "6042      6043.0 2020-04-24          India             21093.259690   \n",
       "6043      6044.0 2020-04-25          India             21989.058140   \n",
       "6044      6045.0 2020-04-26          India             22873.069767   \n",
       "6045      6046.0 2020-04-27          India             23745.294574   \n",
       "6046      6047.0 2020-04-28          India             24605.732558   \n",
       "6047      6048.0 2020-04-29          India             25454.383721   \n",
       "6048      6049.0 2020-04-30          India             26291.248062   \n",
       "6049      6050.0 2020-05-01          India             27116.325581   \n",
       "6050      6051.0 2020-05-02          India             27929.616279   \n",
       "6051      6052.0 2020-05-03          India             28731.120155   \n",
       "6052      6053.0 2020-05-04          India             29520.837209   \n",
       "6053      6054.0 2020-05-05          India             30298.767442   \n",
       "6054      6055.0 2020-05-06          India             31064.910853   \n",
       "6055      6056.0 2020-05-07          India             31819.267442   \n",
       "6056      6057.0 2020-05-08          India             32561.837209   \n",
       "6057      6058.0 2020-05-09          India             33292.620155   \n",
       "6058      6059.0 2020-05-10          India             34011.616279   \n",
       "6059      6060.0 2020-05-11          India             34718.825581   \n",
       "6060      6061.0 2020-05-12          India             35414.248062   \n",
       "6061      6062.0 2020-05-13          India             36097.883721   \n",
       "6062      6063.0 2020-05-14          India             36769.732558   \n",
       "\n",
       "      Fatalities_test_mad  \n",
       "6020                  NaN  \n",
       "6021                  NaN  \n",
       "6022                  NaN  \n",
       "6023                  NaN  \n",
       "6024                  NaN  \n",
       "6025                  NaN  \n",
       "6026                  NaN  \n",
       "6027                  NaN  \n",
       "6028                  NaN  \n",
       "6029                  NaN  \n",
       "6030                  NaN  \n",
       "6031                  NaN  \n",
       "6032                  NaN  \n",
       "6033           428.000000  \n",
       "6034           462.593023  \n",
       "6035           496.779070  \n",
       "6036           530.558140  \n",
       "6037           563.930233  \n",
       "6038           596.895349  \n",
       "6039           629.453488  \n",
       "6040           661.604651  \n",
       "6041           693.348837  \n",
       "6042           724.686047  \n",
       "6043           755.616279  \n",
       "6044           786.139535  \n",
       "6045           816.255814  \n",
       "6046           845.965116  \n",
       "6047           875.267442  \n",
       "6048           904.162791  \n",
       "6049           932.651163  \n",
       "6050           960.732558  \n",
       "6051           988.406977  \n",
       "6052          1015.674419  \n",
       "6053          1042.534884  \n",
       "6054          1068.988372  \n",
       "6055          1095.034884  \n",
       "6056          1120.674419  \n",
       "6057          1145.906977  \n",
       "6058          1170.732558  \n",
       "6059          1195.151163  \n",
       "6060          1219.162791  \n",
       "6061          1242.767442  \n",
       "6062          1265.965116  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[test[\"Country_Region\"]==\"India\", [\"ForecastId\", \"Date\", \"Country_Region\", \"ConfirmedCases_test_mad\", \"Fatalities_test_mad\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ForecastId</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "      <th>Fatalities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6030</th>\n",
       "      <td>6031</td>\n",
       "      <td>9205.000000</td>\n",
       "      <td>331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6031</th>\n",
       "      <td>6032</td>\n",
       "      <td>10453.000000</td>\n",
       "      <td>358.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6032</th>\n",
       "      <td>6033</td>\n",
       "      <td>11487.000000</td>\n",
       "      <td>393.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6033</th>\n",
       "      <td>6034</td>\n",
       "      <td>12475.835039</td>\n",
       "      <td>427.945054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6034</th>\n",
       "      <td>6035</td>\n",
       "      <td>13492.152281</td>\n",
       "      <td>462.906669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>6036</td>\n",
       "      <td>14481.338577</td>\n",
       "      <td>498.126895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6037</td>\n",
       "      <td>15438.844691</td>\n",
       "      <td>533.703935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6038</td>\n",
       "      <td>16438.258943</td>\n",
       "      <td>568.535186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6039</td>\n",
       "      <td>17460.609017</td>\n",
       "      <td>604.639302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6040</td>\n",
       "      <td>18434.896594</td>\n",
       "      <td>640.217808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6040</th>\n",
       "      <td>6041</td>\n",
       "      <td>19416.579121</td>\n",
       "      <td>679.311775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6041</th>\n",
       "      <td>6042</td>\n",
       "      <td>20433.811527</td>\n",
       "      <td>716.578935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6042</th>\n",
       "      <td>6043</td>\n",
       "      <td>21328.706735</td>\n",
       "      <td>756.626860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>6044</td>\n",
       "      <td>22185.228235</td>\n",
       "      <td>801.154560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044</th>\n",
       "      <td>6045</td>\n",
       "      <td>23166.279246</td>\n",
       "      <td>835.573619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>6046</td>\n",
       "      <td>24142.930889</td>\n",
       "      <td>881.079705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>6047</td>\n",
       "      <td>25194.026582</td>\n",
       "      <td>912.578752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>6048</td>\n",
       "      <td>25916.250184</td>\n",
       "      <td>954.171727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>6049</td>\n",
       "      <td>26886.909492</td>\n",
       "      <td>988.505190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>6050</td>\n",
       "      <td>27420.961107</td>\n",
       "      <td>1047.219192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050</th>\n",
       "      <td>6051</td>\n",
       "      <td>28087.098266</td>\n",
       "      <td>1122.479898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6051</th>\n",
       "      <td>6052</td>\n",
       "      <td>28855.835872</td>\n",
       "      <td>1165.373343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>6053</td>\n",
       "      <td>29537.077187</td>\n",
       "      <td>1222.583722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>6054</td>\n",
       "      <td>30251.651976</td>\n",
       "      <td>1297.401139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>6055</td>\n",
       "      <td>31021.939538</td>\n",
       "      <td>1336.857310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>6056</td>\n",
       "      <td>31755.110480</td>\n",
       "      <td>1372.797031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6056</th>\n",
       "      <td>6057</td>\n",
       "      <td>32753.258762</td>\n",
       "      <td>1393.823900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>6058</td>\n",
       "      <td>33820.130124</td>\n",
       "      <td>1377.962295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6058</th>\n",
       "      <td>6059</td>\n",
       "      <td>35039.593114</td>\n",
       "      <td>1433.833824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6059</th>\n",
       "      <td>6060</td>\n",
       "      <td>35669.079895</td>\n",
       "      <td>1447.725330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6060</th>\n",
       "      <td>6061</td>\n",
       "      <td>36962.702455</td>\n",
       "      <td>1461.388802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>6062</td>\n",
       "      <td>38183.573913</td>\n",
       "      <td>1477.040012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>6063</td>\n",
       "      <td>39050.721870</td>\n",
       "      <td>1515.258334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ForecastId  ConfirmedCases   Fatalities\n",
       "6030        6031     9205.000000   331.000000\n",
       "6031        6032    10453.000000   358.000000\n",
       "6032        6033    11487.000000   393.000000\n",
       "6033        6034    12475.835039   427.945054\n",
       "6034        6035    13492.152281   462.906669\n",
       "6035        6036    14481.338577   498.126895\n",
       "6036        6037    15438.844691   533.703935\n",
       "6037        6038    16438.258943   568.535186\n",
       "6038        6039    17460.609017   604.639302\n",
       "6039        6040    18434.896594   640.217808\n",
       "6040        6041    19416.579121   679.311775\n",
       "6041        6042    20433.811527   716.578935\n",
       "6042        6043    21328.706735   756.626860\n",
       "6043        6044    22185.228235   801.154560\n",
       "6044        6045    23166.279246   835.573619\n",
       "6045        6046    24142.930889   881.079705\n",
       "6046        6047    25194.026582   912.578752\n",
       "6047        6048    25916.250184   954.171727\n",
       "6048        6049    26886.909492   988.505190\n",
       "6049        6050    27420.961107  1047.219192\n",
       "6050        6051    28087.098266  1122.479898\n",
       "6051        6052    28855.835872  1165.373343\n",
       "6052        6053    29537.077187  1222.583722\n",
       "6053        6054    30251.651976  1297.401139\n",
       "6054        6055    31021.939538  1336.857310\n",
       "6055        6056    31755.110480  1372.797031\n",
       "6056        6057    32753.258762  1393.823900\n",
       "6057        6058    33820.130124  1377.962295\n",
       "6058        6059    35039.593114  1433.833824\n",
       "6059        6060    35669.079895  1447.725330\n",
       "6060        6061    36962.702455  1461.388802\n",
       "6061        6062    38183.573913  1477.040012\n",
       "6062        6063    39050.721870  1515.258334"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub0.loc[sub0.ForecastId.between(6031, 6063)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ForecastId</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "      <th>Fatalities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>281.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>299.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>349.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>367.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ForecastId  ConfirmedCases  Fatalities\n",
       "0           1           273.0         6.0\n",
       "1           2           281.0         6.0\n",
       "2           3           299.0         7.0\n",
       "3           4           349.0         7.0\n",
       "4           5           367.0        11.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub0.to_csv(\"submission.csv\",index=False)\n",
    "sub0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ForecastId        0\n",
       "ConfirmedCases    0\n",
       "Fatalities        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub0.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
